modelName = "Logistic-Simulated1", nSubj = n_subj_1, nStim = n_stim_1)
Gaus_Post_Preds <- Posterior_Preds(samples = gaus_samples_2, responses = responses_2,
modelName = "Gaussian-Simulated2", nSubj = n_subj_2, nStim = n_stim_2)
Logis_Post_Preds <- Posterior_Preds(samples = logis_samples_2, responses = responses_2,
modelName = "Logistic-Simulated2", nSubj = n_subj_2, nStim = n_stim_2)
gaus_output_1$waic
Model_Comps <- function(models) {
# This function takes as input a list of model output and omputes Widely
# Applicable Information Criterions and marginal likelihoods for each model
# and saves the output to file.
bridge <- list()
waics <- list()
for (i in 1:length(models)) {
# bridge[i] <- list(models[[i]][["bridge"]])
waics[i] <- models[[i]][["waic"]]# [["estimates"]][3,1]
}
BFs <- matrix(NA, nrow = length(models), ncol = length(models))
rownames(BFs) <- colnames(BFs) <- names(models)
# for (row in 1:length(models)) {
#   for (col in 1:length(models)) {
#     BFs[row, col] <- bf(bridge[[row]], bridge[[col]])[["bf"]]
#   }
# }
waics <- data.frame(t(c(unlist(waics))))
colnames(waics) <- names(models)
write.csv(waics, file = paste0(file_name_root, "WAICs", ".csv"), row.names = FALSE)
write.csv(BFs, file = paste0(file_name_root, "BFs", ".csv"))
return(list(waics, BFs))
}
# 3. model comparison
out_list_1 <- list(gaus_output_1, logis_output_1)
names(out_list_1) <- c("gaussian", "logistic")
Model_Comps(models = out_list_1)
gaus_output_1$waic
logis_output_1$waic
logis_output_2$waic
gaus_output_2$waic
hist(gaus_samples_1$M, breaks = 1000)
hist(gaus_samples_2$M, breaks = 1000)
hist(gaus_samples_1$M, breaks = 1000)
abline(v = mean(gaus_samples_1$M), col = "red", lwd = 3)
gaus_output_1$waic
logis_output_1$waic
gaus_output_2$waic
logis_output_2$waic
summary <- rstan::summary(gaus_output_1$stanfit, probs = c(0.025, 0.50, 0.975))$summary
write.csv(summary, file = paste0(file_name_root, "gaus1-summary.csv"), row.names = TRUE)
summary <- rstan::summary(logis_output_1$stanfit, probs = c(0.025, 0.50, 0.975))$summary
write.csv(summary, file = paste0(file_name_root, "logis1-summary.csv"), row.names = TRUE)
?bf
bf(1, .5)
log(1)
log(10)
bf(2.302585, 0)
#-------------------------------------------------------------------------------
#                     FITTING GENERALIZATION GRADIENTS
#-------------------------------------------------------------------------------
# Jessica Lee 2019
seed_num <- 1000
set.seed(seed_num)
mc.cores = parallel::detectCores()
file_name_root <- "output/"
# load packages
library(tidyverse)
library(gridExtra)
library(rstan)
# mcmc parameters
n_chains <- 4
n_iter <- 10000
n_burnin <- 1000
n_thin <- 1
n_samp <- 100
# figures
graph_file_type = ".jpeg"
fig_cols <- c("black", "red")
scat_shape <- 16
scat_size <- 1
scat_col <- alpha(fig_cols[2], .1)
gg_height <- 10
gg_width <- 10
dpi = 600
n_row <- 5
dim_vals <- seq(-.5, +.5, .1)
# source
source("R/functions.R")
source("models/models.R")
# ------------------------------ SIMULATED DATA --------------------------------
simulate <- Simulate_Data(M = rep(c(-.2, -.1, 0, .1, .2), times = 5),
SD = rep(c(.1, .15, .2, .3, .5), each = 5),
simHeight = rep(75, 25), dimVals = dim_vals,
noise = 7.5, nSubj = 25)
simulate$fig
demo_data <- simulate$data
write.csv(demo_data, file = paste0("data/","demo_data.csv"), row.names = FALSE)
# 1. read data
demo <- Read_Demo(fileName = paste0("data/","demo_data.csv"), dimVals = seq(-.5, +.5, .1))
data_list <- demo[[1]]
# 2. fit models
demo_output <- Run_Gaussian_Mod(data_list, modelName = "demo")
demo_samples <- demo_output[["samples"]]
# 3. posterior predictives
Gaus_Post_Preds <- Posterior_Preds(samples = demo_samples, responses = demo[[4]],
modelName = "demo", nSubj = demo[[2]],
nStim = demo[[3]], summary = as.data.frame(demo_output$summary))
mean_line_cols <- c("red", "blue")
density_cols <- c("red", "blue")
source('/Volumes/JessUSB/projects/2017-gen_analysis/code/curve_fitting/code/R/functions.R', echo=TRUE)
# 1. read data
data <- Read_Subgroups(fileName = "data/NSW02-Data.csv", dimVals = dim_vals)
data_list_sim <- data[[1]]
data_list_lin <- data[[5]]
# 2. fit models for similarity and linear subgroup
sim_output <- Run_Gaussian_Mod(data_list_sim, modelName = "sim")
sim_samples <- sim_output[["samples"]]
lin_output <- Run_Gaussian_Mod(data_list_lin, modelName = "lin")
lin_samples <- lin_output[["samples"]]
# 3. posterior predictives
Posterior_Preds(samples = sim_samples, responses = data[[4]], modelName = "sim",
nSubj = data[[2]], nStim = data[[3]], summary = as.data.frame(sim_output$summary))
Posterior_Preds(samples = lin_samples, responses = data[[8]], modelName = "lin",
nSubj = data[[6]], nStim = data[[3]], summary = as.data.frame(lin_output$summary))
# 4. compare estimates between groups
Compare_Subgroups(sim_samples, lin_samples, "similarity", "linear")
Compare_Subgroups <- function(samples1, samples2, groupName1, groupName2) {
estimates <- as.data.frame(cbind(c(as.vector(samples1$M), as.vector(samples2$M)),
c(as.vector(samples1$SD), as.vector(samples2$SD)),
c(as.vector(samples1$height), as.vector(samples2$height))))
colnames(estimates) <- c("M", "SD", "height")
estimates$group <- c(rep(groupName1, length(as.vector(sim_samples$M))),
rep(groupName2, length(as.vector(lin_samples$M))))
density_layers <- list(geom_density(alpha = .5, show.legend = FALSE),
scale_fill_manual(values = density_cols),
theme_classic())
M_fig <- ggplot(estimates, aes(M, fill = group)) +
density_layers +
geom_vline(xintercept = mean(samples1$M), linetype = "solid", colour = density_cols[1]) +
geom_vline(xintercept = mean(samples2$M), linetype = "solid", colour = density_cols[2]) +
ggtitle("a) Mean")
SD_fig <- ggplot(estimates, aes(SD, fill = group)) +
density_layers +
geom_vline(xintercept = mean(samples1$SD), linetype = "solid", colour = density_cols[1]) +
geom_vline(xintercept = mean(samples2$SD), linetype = "solid", colour = density_cols[2]) +
ggtitle("b) Width")
height_fig <- ggplot(estimates, aes(height, fill = group)) +
density_layers +
geom_vline(xintercept = mean(samples1$height), linetype = "solid", colour = density_cols[1]) +
geom_vline(xintercept = mean(samples2$height), linetype = "solid", colour = density_cols[2]) +
ggtitle("c) Height")
fig_panel <- grid.arrange(M_fig + theme(legend.title = element_blank()),
SD_fig + theme(legend.title = element_blank()),
height_fig, nrow = 1)
ggsave(paste0(file_name_root, "density", graph_file_type), fig_panel,
"jpeg", height = gg_height, width = gg_width*3, units = "cm", dpi = dpi)
}
# 4. compare estimates between groups
Compare_Subgroups(sim_samples, lin_samples, "similarity", "linear")
Compare_Subgroups <- function(samples1, samples2, groupName1, groupName2) {
estimates <- as.data.frame(cbind(c(as.vector(samples1$M), as.vector(samples2$M)),
c(as.vector(samples1$SD), as.vector(samples2$SD)),
c(as.vector(samples1$height), as.vector(samples2$height))))
colnames(estimates) <- c("M", "SD", "height")
estimates$group <- c(rep(groupName1, length(as.vector(sim_samples$M))),
rep(groupName2, length(as.vector(lin_samples$M))))
density_layers <- list(geom_density(alpha = .25, show.legend = FALSE),
scale_fill_manual(values = density_cols),
theme_classic())
M_fig <- ggplot(estimates, aes(M, fill = group)) +
density_layers +
geom_vline(xintercept = mean(samples1$M), linetype = "solid", colour = density_cols[1]) +
geom_vline(xintercept = mean(samples2$M), linetype = "solid", colour = density_cols[2]) +
ggtitle("a) Mean")
SD_fig <- ggplot(estimates, aes(SD, fill = group)) +
density_layers +
geom_vline(xintercept = mean(samples1$SD), linetype = "solid", colour = density_cols[1]) +
geom_vline(xintercept = mean(samples2$SD), linetype = "solid", colour = density_cols[2]) +
ggtitle("b) Width")
height_fig <- ggplot(estimates, aes(height, fill = group)) +
density_layers +
geom_vline(xintercept = mean(samples1$height), linetype = "solid", colour = density_cols[1]) +
geom_vline(xintercept = mean(samples2$height), linetype = "solid", colour = density_cols[2]) +
ggtitle("c) Height") +
theme(legend.position="right")
fig_panel <- grid.arrange(M_fig + theme(legend.title = element_blank()),
SD_fig + theme(legend.title = element_blank()),
height_fig, nrow = 1)
ggsave(paste0(file_name_root, "density", graph_file_type), fig_panel,
"jpeg", height = gg_height, width = gg_width*3, units = "cm", dpi = dpi)
}
# 4. compare estimates between groups
Compare_Subgroups(sim_samples, lin_samples, "similarity", "linear")
Compare_Subgroups <- function(samples1, samples2, groupName1, groupName2) {
estimates <- as.data.frame(cbind(c(as.vector(samples1$M), as.vector(samples2$M)),
c(as.vector(samples1$SD), as.vector(samples2$SD)),
c(as.vector(samples1$height), as.vector(samples2$height))))
colnames(estimates) <- c("M", "SD", "height")
estimates$group <- c(rep(groupName1, length(as.vector(sim_samples$M))),
rep(groupName2, length(as.vector(lin_samples$M))))
density_layers <- list(geom_density(alpha = .25),
scale_fill_manual(values = density_cols),
theme_classic())
M_fig <- ggplot(estimates, aes(M, fill = group)) +
density_layers +
guides(fill = FALSE) +
geom_vline(xintercept = mean(samples1$M), linetype = "solid", colour = density_cols[1],
size = 2) +
geom_vline(xintercept = mean(samples2$M), linetype = "solid", colour = density_cols[2],
size = 2) +
ggtitle("a) Mean")
SD_fig <- ggplot(estimates, aes(SD, fill = group)) +
density_layers +
guides(fill = FALSE) +
geom_vline(xintercept = mean(samples1$SD), linetype = "solid", colour = density_cols[1],
size = 2) +
geom_vline(xintercept = mean(samples2$SD), linetype = "solid", colour = density_cols[2],
size = 2) +
ggtitle("b) Width")
height_fig <- ggplot(estimates, aes(height, fill = group)) +
density_layers +
geom_vline(xintercept = mean(samples1$height), linetype = "solid", colour = density_cols[1],
size = 2) +
geom_vline(xintercept = mean(samples2$height), linetype = "solid", colour = density_cols[2],
size = 2) +
ggtitle("c) Height") +
theme(legend.position="right")
fig_panel <- grid.arrange(M_fig + theme(legend.title = element_blank()),
SD_fig + theme(legend.title = element_blank()),
height_fig, nrow = 1)
ggsave(paste0(file_name_root, "density", graph_file_type), fig_panel,
"jpeg", height = gg_height, width = gg_width*3, units = "cm", dpi = dpi)
}
# 4. compare estimates between groups
Compare_Subgroups(sim_samples, lin_samples, "similarity", "linear")
density_cols <- c("blue", "red") # linear, similarity
# 4. compare estimates between groups
Compare_Subgroups(sim_samples, lin_samples, "similarity", "linear")
# 4. compare estimates between groups
Compare_Subgroups(lin_samples, sim_samples, "linear", "similarity")
#-------------------------------------------------------------------------------
#                     FITTING GENERALIZATION GRADIENTS
#-------------------------------------------------------------------------------
# Jessica Lee 2019
seed_num <- 1000
set.seed(seed_num)
mc.cores = parallel::detectCores()
file_name_root <- "output/"
# load packages
library(tidyverse)
library(gridExtra)
library(rstan)
# mcmc parameters
n_chains <- 4
n_iter <- 10000
n_burnin <- 1000
n_thin <- 1
n_samp <- 100
# figures
graph_file_type = ".jpeg"
fig_cols <- c("black", "red")
scat_shape <- 16
scat_size <- 1
scat_col <- alpha(fig_cols[2], .1)
gg_height <- 10
gg_width <- 10
dpi = 600
n_row <- 5
density_cols <- c("blue", "red") # linear, similarity
dim_vals <- seq(-.5, +.5, .1)
# source
source("R/functions.R")
source("models/models.R")
# ------------------------------ SIMULATED DATA --------------------------------
simulate <- Simulate_Data(M = rep(c(-.2, -.1, 0, .1, .2), times = 5),
SD = rep(c(.05, .1, .15, .25, .5), each = 5),
simHeight = rep(75, 25), dimVals = dim_vals,
noise = 5, nSubj = 25)
simulate$fig
demo_data <- simulate$data
write.csv(demo_data, file = paste0("data/","demo_data.csv"), row.names = FALSE)
# 1. read data
demo <- Read_Demo(fileName = paste0("data/","demo_data.csv"), dimVals = dim_vals)
data_list <- demo[[1]]
# 2. fit models
demo_output <- Run_Gaussian_Mod(data_list, modelName = "demo")
demo_samples <- demo_output[["samples"]]
# 3. posterior predictives
Gaus_Post_Preds <- Posterior_Preds(samples = demo_samples, responses = demo[[4]],
modelName = "demo", nSubj = demo[[2]],
nStim = demo[[3]],
summary = as.data.frame(demo_output$summary))
n_row
#-------------------------------------------------------------------------------
#                     FITTING GENERALIZATION GRADIENTS
#-------------------------------------------------------------------------------
# Jessica Lee 2019
seed_num <- 1000
set.seed(seed_num)
mc.cores = parallel::detectCores()
file_name_root <- "output/"
# load packages
library(tidyverse)
library(gridExtra)
library(rstan)
# mcmc parameters
n_chains <- 4
n_iter <- 10000
n_burnin <- 1000
n_thin <- 1
n_samp <- 100
# figures
graph_file_type = ".jpeg"
fig_cols <- c("black", "red")
scat_shape <- 16
scat_size <- 1
scat_col <- alpha(fig_cols[2], .1)
gg_height <- 10
gg_width <- 10
dpi = 600
n_row <- 5
n_row_subgroups <- 4
density_cols <- c("blue", "red") # linear, similarity
dim_vals <- seq(-.5, +.5, .1)
# source
source("R/functions.R")
source("models/models.R")
# ------------------------------ SIMULATED DATA --------------------------------
simulate <- Simulate_Data(M = rep(c(-.2, -.1, 0, .1, .2), times = 5),
SD = rep(c(.05, .1, .15, .25, .5), each = 5),
simHeight = rep(75, 25), dimVals = dim_vals,
noise = 5, nSubj = 25)
simulate$fig
demo_data <- simulate$data
write.csv(demo_data, file = paste0("data/","demo_data.csv"), row.names = FALSE)
# 1. read data
demo <- Read_Demo(fileName = paste0("data/","demo_data.csv"), dimVals = dim_vals)
data_list <- demo[[1]]
# 2. fit models
demo_output <- Run_Gaussian_Mod(data_list, modelName = "demo")
demo_samples <- demo_output[["samples"]]
# 3. posterior predictives
Gaus_Post_Preds <- Posterior_Preds(samples = demo_samples, responses = demo[[4]],
modelName = "demo", nSubj = demo[[2]],
nStim = demo[[3]],
summary = as.data.frame(demo_output$summary))
# ----------------------------- SUBGROUP ANALYSIS ------------------------------
# Re-analysis of data from Lee, Hayes, & Lovibond (2018)
# 1. read data
data <- Read_Subgroups(fileName = "data/NSW02-Data.csv", dimVals = dim_vals)
data_list_sim <- data[[1]]
data_list_lin <- data[[5]]
# 2. fit models for similarity and linear subgroup
sim_output <- Run_Gaussian_Mod(data_list_sim, modelName = "sim")
sim_samples <- sim_output[["samples"]]
lin_output <- Run_Gaussian_Mod(data_list_lin, modelName = "lin")
lin_samples <- lin_output[["samples"]]
# 3. posterior predictives
Posterior_Preds(samples = sim_samples, responses = data[[4]], modelName = "sim",
nSubj = data[[2]], nStim = data[[3]], summary = as.data.frame(sim_output$summary))
Posterior_Preds(samples = lin_samples, responses = data[[8]], modelName = "lin",
nSubj = data[[6]], nStim = data[[3]], summary = as.data.frame(lin_output$summary))
# 4. compare estimates between groups
Compare_Subgroups(lin_samples, sim_samples, "linear", "similarity")
# source
source("R/functions.R")
# 1. read data
data <- Read_Groups(fileName = "data/NSW09-Data.csv", dimVals = dim_vals,
group1 = "single", group2 = "distant neg")
Read_Groups <- function(fileName, dimVals, group1, group2) {
# This function reads data in the format specified in the NSW09-Data.csv file and
# prepares the data list to be inputted to stan.
# Requires input for group names as strings
# Note that the "x" column must match the "dimVals" argument in this function.
# For example, if you have 11 stimuli (S1-S11) and the CS+ is the middle
# stimulus (S6), then the position of the CS+ should be 0 in the xs argument,
# and range between -.5 to +.5.
# Note that the range of the xs argument can be changed if needed, but then
# the parameters of the prior distributions must also be changed accordingly
# in stan.
data <- read.csv(fileName, header = TRUE)
# group 1 (single cue)
data_1 <- data %>%
filter(group == group1) %>%
arrange(subj, dimVal)
subj_1 <- data_1[["subj"]]
x_1 <- data_1[["dimVal"]]
y_1 <- data_1[["response"]]
nSubj_1 <- length(unique(subj_1))
nStim_1 <- length(unique(x_1))
responses_1 <- matrix(data_1[["response"]], ncol = nStim_1, byrow = TRUE)
data_list_1 <- list(subj = subj_1,
responses = responses_1,
nSubj = nSubj_1,
nStim = nStim_1,
xs = dimVals)
# group 2 (distant neg)
data_2<- data %>%
filter(group == group2) %>%
arrange(subj, dimVal)
subj_2 <- data_2[["subj"]]
x_2 <- data_2[["dimVal"]]
y_2 <- data_2[["response"]]
nSubj_2 <- length(unique(subj_2))
nStim_2 <- length(unique(x_2))
responses_2 <- matrix(data_2[["response"]], ncol = nStim_2, byrow = TRUE)
data_list_2 <- list(subj = subj_2,
responses = responses_2,
nSubj = nSubj_2,
nStim = nStim_2,
xs = dimVals)
fig <- data %>%
filter(group == group1 | group == group2) %>%
group_by(dimVal, group) %>%
summarise(mean = mean(response)) %>%
ggplot(aes(y = mean, x = dimVal, group = group, colour = group)) +
geom_line() + theme_classic()
ggsave(filename = paste0(file_name_root, "subgroups", graph_file_type), fig,
height = gg_height, width = gg_width, units = "cm")
return(list(data_list_1, nSubj_1, nStim_1, y_1,
data_list_2, nSubj_2, nStim_2, y_2))
}
# 1. read data
data <- Read_Groups(fileName = "data/NSW09-Data.csv", dimVals = dim_vals,
group1 = "single", group2 = "distant neg")
Read_Groups <- function(fileName, dimVals, group1, group2) {
# This function reads data in the format specified in the NSW09-Data.csv file and
# prepares the data list to be inputted to stan.
# Requires input for group names as strings
# Note that the "x" column must match the "dimVals" argument in this function.
# For example, if you have 11 stimuli (S1-S11) and the CS+ is the middle
# stimulus (S6), then the position of the CS+ should be 0 in the xs argument,
# and range between -.5 to +.5.
# Note that the range of the xs argument can be changed if needed, but then
# the parameters of the prior distributions must also be changed accordingly
# in stan.
data <- read.csv(fileName, header = TRUE)
# group 1 (single cue)
data_1 <- data %>%
filter(group == group1) %>%
arrange(subj, dimVal)
subj_1 <- data_1[["subj"]]
x_1 <- data_1[["dimVal"]]
y_1 <- data_1[["response"]]
nSubj_1 <- length(unique(subj_1))
nStim_1 <- length(unique(x_1))
responses_1 <- matrix(data_1[["response"]], ncol = nStim_1, byrow = TRUE)
data_list_1 <- list(subj = subj_1,
responses = responses_1,
nSubj = nSubj_1,
nStim = nStim_1,
xs = dimVals)
# group 2 (distant neg)
data_2<- data %>%
filter(group == group2) %>%
arrange(subj, dimVal)
subj_2 <- data_2[["subj"]]
x_2 <- data_2[["dimVal"]]
y_2 <- data_2[["response"]]
nSubj_2 <- length(unique(subj_2))
nStim_2 <- length(unique(x_2))
responses_2 <- matrix(data_2[["response"]], ncol = nStim_2, byrow = TRUE)
data_list_2 <- list(subj = subj_2,
responses = responses_2,
nSubj = nSubj_2,
nStim = nStim_2,
xs = dimVals)
fig <- data %>%
filter(group == group1 | group == group2) %>%
group_by(dimVal, group) %>%
summarise(mean = mean(response)) %>%
ggplot(aes(y = mean, x = dimVal, group = group, colour = group)) +
geom_line() + theme_classic()
ggsave(filename = paste0(file_name_root, "groups", graph_file_type), fig,
height = gg_height, width = gg_width*1.2, units = "cm")
return(list(data_list_1, nSubj_1, nStim_1, y_1,
data_list_2, nSubj_2, nStim_2, y_2))
}
# 1. read data
data <- Read_Groups(fileName = "data/NSW09-Data.csv", dimVals = dim_vals,
group1 = "single", group2 = "distant neg")
data_list_1 <- data[[1]]
data_list_2 <- data[[5]]
# 2. fit models for each group
group1_output <- Run_Gaussian_Mod(data_list_1, modelName = "group1")
seed_num <- 1000
set.seed(seed_num)
mc.cores = parallel::detectCores()
file_name_root <- "output/"
# load packages
library(tidyverse)
library(gridExtra)
library(rstan)
# mcmc parameters
n_chains <- 4
n_iter <- 10000
n_burnin <- 1000
n_thin <- 1
n_samp <- 100
# figures
graph_file_type = ".jpeg"
fig_cols <- c("black", "red")
scat_shape <- 16
scat_size <- 1
scat_col <- alpha(fig_cols[2], .1)
gg_height <- 10
gg_width <- 10
dpi = 600
n_row <- 5
n_row_subgroups <- 4
density_cols <- c("blue", "red") # linear, similarity
dim_vals <- seq(-.5, +.5, .1)
# source
source("R/functions.R")
source("models/models.R")
